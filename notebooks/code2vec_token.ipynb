{"cells":[{"cell_type":"markdown","metadata":{"id":"bdYBs2jzqND0"},"source":["## Startup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1461,"status":"ok","timestamp":1626336319658,"user":{"displayName":"Sebastian Fabry","photoUrl":"","userId":"07905730873771762041"},"user_tz":-120},"id":"ON_8mt5GQNKC","outputId":"3fe2aaca-4c5d-42bc-fced-d58cbb79f001"},"outputs":[],"source":["!git clone https://github.com/tech-srl/code2vec"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70093,"status":"ok","timestamp":1626336389744,"user":{"displayName":"Sebastian Fabry","photoUrl":"","userId":"07905730873771762041"},"user_tz":-120},"id":"H7RU6JVxosm4","outputId":"7ac5bf32-8710-42dd-9804-d94aa41aa359"},"outputs":[],"source":["!wget https://s3.amazonaws.com/code2vec/model/java14m_model.tar.gz\n","!tar -xvzf java14m_model.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":150932,"status":"ok","timestamp":1626336540667,"user":{"displayName":"Sebastian Fabry","photoUrl":"","userId":"07905730873771762041"},"user_tz":-120},"id":"RL_xfQeioHzG","outputId":"313be4a2-ddce-4193-d688-389578cbbdc4"},"outputs":[],"source":["!python3 code2vec/code2vec.py --load ./models/java14_model/saved_model_iter8.release --save_w2v ./models/java14_model/tokens.txt"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":177694,"status":"ok","timestamp":1626336718358,"user":{"displayName":"Sebastian Fabry","photoUrl":"","userId":"07905730873771762041"},"user_tz":-120},"id":"d3LVcRuJoqdW"},"outputs":[],"source":["from gensim.models import KeyedVectors as word2vec\n","\n","vectors_text_path = 'models/java14_model/tokens.txt'\n","model = word2vec.load_word2vec_format(vectors_text_path, binary=False)"]},{"cell_type":"markdown","metadata":{"id":"n5z1jnriqSoc"},"source":["## Functions"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1626336718361,"user":{"displayName":"Sebastian Fabry","photoUrl":"","userId":"07905730873771762041"},"user_tz":-120},"id":"OdY9pxI300N9"},"outputs":[],"source":["import re\n","\n","def camel_case_split(identifier):\n","    return re.findall('[a-zA-Z][^A-Z]*', identifier)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1626336718362,"user":{"displayName":"Sebastian Fabry","photoUrl":"","userId":"07905730873771762041"},"user_tz":-120},"id":"HRdhHweK4g9_"},"outputs":[],"source":["def camel_to_snake(name):\n","  name = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n","  return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', name).lower()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1626336718362,"user":{"displayName":"Sebastian Fabry","photoUrl":"","userId":"07905730873771762041"},"user_tz":-120},"id":"V95A1n0xBAaD"},"outputs":[],"source":["def get_iss_by_id(id, dicts):\n","    for item in dicts:\n","        if item[\"id\"] == id:\n","            return item\n","    # return next(item for item in dicts if item[\"id\"] == id)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1626336718363,"user":{"displayName":"Sebastian Fabry","photoUrl":"","userId":"07905730873771762041"},"user_tz":-120},"id":"SyxPx7ap6MpT"},"outputs":[],"source":["import numpy as np\n","from gensim.utils import tokenize\n","\n","def code2vec(code):\n","    vecs = []\n","    tokens = list(tokenize(code, deacc=True))\n","    for token in tokens:\n","        # model is only trained on lowercase\n","        # if token in vocab get vector\n","        if token.lower() in model.vocab:\n","            # token = token.lower()\n","            vecs.append(model[token.lower()])\n","        else:\n","            # split the token based on underscore and camelcase to prevent oov\n","            humps = camel_to_snake(token).split(\"_\")\n","            for hump in humps:\n","                # again, lowercase only\n","                hump = hump.lower()\n","                # check if token piece is in vocab\n","                if hump in model.vocab:\n","                    vecs.append(model[hump])\n","    \n","    # average the vecs for the word pieces in this line of code\n","    mean = np.mean(vecs, axis=0)\n","    if not np.isnan(np.sum(mean)):\n","        return mean\n","    else:\n","        return np.zeros(128)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1626336718363,"user":{"displayName":"Sebastian Fabry","photoUrl":"","userId":"07905730873771762041"},"user_tz":-120},"id":"9-WlY4lH-MFG"},"outputs":[],"source":["# line-wise\r\n","def array2vec(taints, sourcesinkonly = False):\r\n","    vecs = []\r\n","    for taint in taints:\r\n","        vecs.append(code2vec(taint['code']))\r\n","    \r\n","    if len(vecs) == 1:\r\n","        return vecs[0]\r\n","    # source and sink only\r\n","    elif sourcesinkonly:\r\n","        values = np.asarray([vecs[0], vecs[-1]], dtype=np.float32)\r\n","        weights = [0.75, 0.25]\r\n","        return np.average(values, axis=0, weights=weights)\r\n","    else:\r\n","        return np.average(vecs, axis=0)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1626336718363,"user":{"displayName":"Sebastian Fabry","photoUrl":"","userId":"07905730873771762041"},"user_tz":-120},"id":"FCCiHT-gv9ci"},"outputs":[],"source":["# block-wise\r\n","def array2vec(snippet, sourcesinkonly = False):\r\n","    snippet = [i[\"code\"] for i in snippet]\r\n","    # snippet = snippet[::-1]\r\n","    code = \"\\n\".join(snippet)\r\n","    vec = code2vec(code)\r\n","    return vec"]},{"cell_type":"markdown","metadata":{"id":"soWgsMl5_80W"},"source":["## Calculating Embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":609,"status":"ok","timestamp":1623076158436,"user":{"displayName":"Sebastian Fabry","photoUrl":"","userId":"07905730873771762041"},"user_tz":-120},"id":"PXTGUcjdRCOe","outputId":"bf8c4b56-593a-4dd1-b985-d99079304d0f"},"outputs":[],"source":["import json\r\n","\r\n","with open('../output/java_features.json', encoding=\"utf-8\") as json_file:\r\n","    feats = json.load(json_file)\r\n","\r\n","for iss in feats:\r\n","    if \"cleared\" in iss and len(iss[\"cleared\"]) > 0:\r\n","        vec_cleared = array2vec(iss[\"cleared\"])\r\n","    else:\r\n","        continue\r\n","    iss['embedding'] = vec_cleared"]},{"cell_type":"markdown","metadata":{"id":"ZP99JG9opw8W"},"source":["## Evaluation 4\n","Check a0 against all others. Look at the majority of rankings inside the |A| window. Assign label."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iW00xNODp7jk"},"outputs":[],"source":["import torch\n","from torch import nn\n","import operator\n","import copy\n","from scipy import spatial\n","\n","# compare all issues to a query. first similar should be from same category.\n","def evaluate_categories_3(categories, feats, category_check=True):\n","    cos = nn.CosineSimilarity(dim=0)\n","\n","    # measures per category\n","    measures = [{\n","        \"tp\": 0,\n","        \"fp\": 0,\n","        \"fn\": 0,\n","    } for _ in range(len(categories))]\n","\n","    # loop through all categories\n","    for (i_cat, category) in enumerate(categories):\n","        for (i_query, query_id) in enumerate(category):\n","            # put all similarity results in this array\n","            results = []\n","\n","            query = get_iss_by_id(query_id, feats)\n","            others = copy.deepcopy(categories)\n","            del others[i_cat][i_query]\n","\n","            # compare to all other issues\n","            for i_check, check_cat in enumerate(others):\n","                for check_iss in check_cat:\n","                    check = get_iss_by_id(check_iss, feats)\n","                    sim = 1 - spatial.distance.cosine(check['embedding'], query['embedding'])\n","                    # sim = cos(torch.Tensor(check['embedding']), torch.Tensor(query['embedding']))\n","                    results.append({\n","                        \"bucket\": i_check,\n","                        \"similarity\": sim\n","                    })\n","            \n","            # sort results by similarity score\n","            results = sorted(results, key=lambda k: k['similarity'], reverse=True)\n","            # we only care about the results inside the bucket size\n","            results = results[:len(category) - 1]\n","            # check majority category of results\n","            counts = dict()\n","            for i in results:\n","                counts[i['bucket']] = counts.get(i['bucket'], 0) + 1\n","            majority = max(counts.items(), key=operator.itemgetter(1))[0]\n","\n","            if i_cat == majority:\n","                measures[i_cat]['tp'] += 1\n","            else:\n","                measures[i_cat]['fn'] += 1\n","                measures[majority]['fp'] += 1\n","\n","    return measures"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":563,"status":"ok","timestamp":1623076165528,"user":{"displayName":"Sebastian Fabry","photoUrl":"","userId":"07905730873771762041"},"user_tz":-120},"id":"tAhf2rHPVUX2","outputId":"9d2eeb14-0847-4d85-9f28-3ee6814f8397"},"outputs":[],"source":["with open('../data/label_java_sqli.json') as json_file:\r\n","    categories = json.load(json_file)\r\n","\r\n","measures = evaluate_categories_3(categories, feats)\r\n","for measure in measures:\r\n","    precision = measure['tp'] / (measure['tp'] + measure['fp']) if (measure['tp'] + measure['fp']) else 0\r\n","    recall = measure['tp'] / (measure['tp'] + measure['fn']) if (measure['tp'] + measure['fn']) else 0\r\n","    f1 = 2 * ((precision * recall) / (precision + recall)) if (precision + recall) else 0\r\n","    beta = 2\r\n","    f_beta = (1 + beta**2) * ((precision * recall) / (beta**2 * precision + recall)) if (precision + recall) else 0\r\n","    \r\n","    print(f\"F1: {f1}\")\r\n","    print(\"-----------\")"]},{"cell_type":"markdown","metadata":{"id":"v0QZelpNqE78"},"source":["## Evaluation 5\n","Check a0 against all others. Look at rank 1 and apply label."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VOa_oPJDqTpE"},"outputs":[],"source":["from torch import nn\n","import operator\n","import copy\n","\n","# compare all issues to a query. first similar should be from same category.\n","def evaluate_categories_4(categories, feats, threshold = 1):\n","    cos = nn.CosineSimilarity(dim=0)\n","\n","    # measures per category\n","    measures = [{\n","        \"true\": 0,\n","        \"false\": 0,\n","    } for _ in range(len(categories))]\n","\n","    # loop through all categories\n","    for (i_cat, category) in enumerate(categories):\n","        for (i_query, query_id) in enumerate(category):\n","            # put all similarity results in this array\n","            results = []\n","\n","            query = get_iss_by_id(query_id, feats)\n","            others = copy.deepcopy(categories)\n","            del others[i_cat][i_query]\n","\n","            # compare to all other issues\n","            for i_check_cat, check_cat in enumerate(others):\n","                for check_iss in check_cat:\n","                    check = get_iss_by_id(check_iss, feats)\n","                    sim = cos(torch.Tensor(check['embedding']), torch.Tensor(query['embedding']))\n","                    results.append({\n","                        \"bucket\": i_check_cat == i_cat,\n","                        \"similarity\": sim\n","                    })\n","            \n","            # sort results by similarity score\n","            results = sorted(results, key=lambda k: k['similarity'], reverse=True)\n","\n","            # check if one under the first threshold results comes from the same category\n","            found = False\n","            for i in range(threshold):\n","                if results[i][\"bucket\"] == True:\n","                    measures[i_cat][\"true\"] += 1\n","                    found = True\n","                    break\n","            if found == False:\n","                measures[i_cat][\"false\"] += 1\n","    \n","    return measures"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18130,"status":"ok","timestamp":1623076206902,"user":{"displayName":"Sebastian Fabry","photoUrl":"","userId":"07905730873771762041"},"user_tz":-120},"id":"ujeTxm2FIA3p","outputId":"53b64661-638c-40a7-92b4-c609b9f8ce6e"},"outputs":[],"source":["%matplotlib inline\r\n","import matplotlib.pyplot as plt\r\n","\r\n","with open('../data/label_java_xss.json') as json_file:\r\n","    categories = json.load(json_file)\r\n","\r\n","limit = 20\r\n","accuracies = [ [] for _ in range(len(categories)) ]\r\n","\r\n","# for threshold in range(1, limit):\r\n","for threshold in [1, 3, 5]:\r\n","    print(f\"Threshold: {threshold}\")\r\n","    measures = evaluate_categories_4(categories, feats, threshold)\r\n","    for i_cat, cat in enumerate(measures):\r\n","        print(f\"Kategorie {i_cat + 1}\")\r\n","        print(cat['true'] / (cat['true'] + cat['false']))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMUahiWpzh8wRZaFt//TGhu","collapsed_sections":["RCgpx0qCV1vN"],"name":"code2vec.ipynb","provenance":[]},"interpreter":{"hash":"8ab0d968002a578cf1e1aa041721a175249ba338f6da29efa5ef1a380c630376"},"kernelspec":{"display_name":"Python 3.8.3 64-bit ('ProgramData': virtualenv)","name":"python3"},"language_info":{"name":"python","version":""}},"nbformat":4,"nbformat_minor":0}